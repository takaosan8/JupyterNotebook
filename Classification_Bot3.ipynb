{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crassification Bot\n",
    "　　　From SIGNATE　【練習問題】ボットの判別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ SIGNATEから元データの再配布が認められていないため、このノートブックで解析している元データ(csvファイル、tsvファイル)については、お手数ですがSIGNATEの【練習問題】サイトからダウンロードして、このipynbファイルと同じ場所に入れてから実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.tsvの読み込み\n",
    "df_train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスとbot（目的変数）を説明変数から削除してtrainXに代入する\n",
    "trainX = df_train.iloc[:, 2:]\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 項目間の相関を確認\n",
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 項目間の相関をプロット\n",
    "sns.pairplot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# botカラムとの相関が±0.25以上のカラムのみ代入\n",
    "trainX2 = df_train[[\"default_profile\",\"default_profile_image\",\"geo_enabled\",\"mean_mins_between_tweets\"]]\n",
    "trainX2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot（目的変数）をyに代入する\n",
    "y = df_train.iloc[:, [1]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.tsvの読み込み\n",
    "df_test = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = df_test.iloc[:, 1:]\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# botカラムとの相関が±0.25以上のカラムのみ代入\n",
    "testX2 = df_test[[\"default_profile\",\"default_profile_image\",\"geo_enabled\",\"mean_mins_between_tweets\"]]\n",
    "testX2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検証　Holdout法\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(trainX,\n",
    "                                                 y,\n",
    "                                                 test_size=0.30,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整形\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# set pipelines for three different algorithms\n",
    "pipe_LR = Pipeline([('scl',StandardScaler()),\n",
    "                       ('est',LogisticRegression(random_state=1))])\n",
    "pipe_RF = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',RandomForestClassifier(random_state=1))])\n",
    "pipe_GB = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',GradientBoostingClassifier(random_state=1))])\n",
    "pipe_PCARF = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',PCA(random_state=1)),\n",
    "                          ('rfc',RandomForestClassifier(random_state=1))])\n",
    "pipe_SVC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',LinearSVC(random_state=1))])\n",
    "pipe_KNC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "pipe_LR.fit(X_train, y_train)\n",
    "pipe_RF.fit(X_train, y_train)\n",
    "pipe_GB.fit(X_train, y_train)\n",
    "pipe_PCARF.fit(X_train, y_train)\n",
    "pipe_SVC.fit(X_train, y_train)\n",
    "pipe_KNC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe_LR_Train:0.470\n",
      "pipe_LR_Test:0.396\n",
      "pipe_RF_Train:0.964\n",
      "pipe_RF_Test:0.648\n",
      "pipe_GB_Train:0.962\n",
      "pipe_GB_Test:0.720\n",
      "pipe_PCARF_Train:0.961\n",
      "pipe_PCARF_Test:0.490\n",
      "pipe_SVC_Train:0.412\n",
      "pipe_SVC_Test:0.349\n",
      "pipe_KNC_Train:0.580\n",
      "pipe_KNC_Test:0.431\n"
     ]
    }
   ],
   "source": [
    "# 評価（f1スコアとする）\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('pipe_LR_Train:%.3f'% f1_score(y_train,\n",
    "                                          pipe_LR.predict(X_train)))\n",
    "print('pipe_LR_Test:%.3f' % f1_score(y_test,\n",
    "                                          pipe_LR.predict(X_test)))\n",
    "\n",
    "print('pipe_RF_Train:%.3f'% f1_score(y_train,\n",
    "                                          pipe_RF.predict(X_train)))\n",
    "print('pipe_RF_Test:%.3f' % f1_score(y_test,\n",
    "                                          pipe_RF.predict(X_test)))\n",
    "\n",
    "print('pipe_GB_Train:%.3f'% f1_score(y_train,\n",
    "                                          pipe_GB.predict(X_train)))\n",
    "print('pipe_GB_Test:%.3f' % f1_score(y_test,\n",
    "                                          pipe_GB.predict(X_test)))\n",
    "\n",
    "print('pipe_PCARF_Train:%.3f'% f1_score(y_train,\n",
    "                                          pipe_PCARF.predict(X_train)))\n",
    "print('pipe_PCARF_Test:%.3f' % f1_score(y_test,\n",
    "                                          pipe_PCARF.predict(X_test)))\n",
    "\n",
    "print('pipe_SVC_Train:%.3f'% f1_score(y_train,\n",
    "                                          pipe_SVC.predict(X_train)))\n",
    "print('pipe_SVC_Test:%.3f' % f1_score(y_test,\n",
    "                                          pipe_SVC.predict(X_test)))\n",
    "\n",
    "print('pipe_KNC_Train:%.3f'% f1_score(y_train,\n",
    "                                          pipe_KNC.predict(X_train)))\n",
    "print('pipe_KNC_Test:%.3f' % f1_score(y_test,\n",
    "                                          pipe_KNC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier を採用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータグリッドの設定\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_GB = {'est__loss':['deviance','exponential'],\n",
    "#                  'est__learning_rate':[0.001,0.01,0.1],\n",
    "#                  'est__n_estimators':[5,10,50,100,500], \n",
    "                 'est__max_depth':[1,2,3,4,5],\n",
    "                 'est__min_samples_split':[0.1,0.3,0.5,0.7,0.9],\n",
    "                 'est__min_samples_leaf':[1,2,4,6,8] }\n",
    "\n",
    "# loss：最小化にするための費用関数　標準値deviance\n",
    "# learning_rate：標準値0.1　結果に対する各ツリーの影響度を小さくする。↓に反比例。小さいほどロバスト性が高く良い\n",
    "# n_estimators：標準値100　逐次的にフィットするためrのツリー数↑に対して交差検証から調整 \n",
    "# max_depth：標準値設定なし　各ツリーの最大深さ　\n",
    "# min_samples_split：標準値2　ノードとして必要な最小サンプル数\n",
    "# min_samples_leaf：標準値1　リーフとして必要な最小サンプル数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "探索空間:{'est__loss': ['deviance', 'exponential'], 'est__max_depth': [1, 2, 3, 4, 5], 'est__min_samples_split': [0.1, 0.3, 0.5, 0.7, 0.9], 'est__min_samples_leaf': [1, 2, 4, 6, 8]}\n",
      "Best Score: 0.728403353386644\n",
      "Best Params {'est__loss': 'exponential', 'est__max_depth': 4, 'est__min_samples_leaf': 8, 'est__min_samples_split': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# write your answer\n",
    "print('探索空間:%s' %param_grid_GB)\n",
    "clf = GridSearchCV(estimator=pipe_GB,\n",
    "                   param_grid=param_grid_GB,\n",
    "                   scoring='f1',\n",
    "                   cv=3,\n",
    "                   return_train_score=False)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print('Best Score:', clf.best_score_)\n",
    "print('Best Params', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipe_GB.predict(testX)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出用CSVの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submit.csv\",header=None)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[1]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"submit3.csv\",index=None,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
