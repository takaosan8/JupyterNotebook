{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crassification Iris\n",
    "　　　From SIGNATE　【練習問題】アヤメの分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.tsvの読み込み\n",
    "train_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスとy（目的変数）を説明変数から削除して、特徴量のみをtrainXに代入する\n",
    "trainX = train_df.iloc[:, 1:-1]\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列の桁数確認\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎統計量の確認\n",
    "trainX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 統計量からわかること\n",
    "- 特徴量は４つのみ (がく片の長さ、がく片の幅、花弁の長さ、花弁の幅)\n",
    "- 特徴量の中では sepal width in cm (がく片の長さ)のバラつきが比較的小さい\n",
    "- 特徴量の中では petal length in cm (花弁の長さ)のバラつきが比較的大きい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型の確認\n",
    "trainX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべて小数点型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データに欠損値はないことを確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainデータの目的変数をyに代入する\n",
    "y = train_df.iloc[:,[5]]\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数の正解ラベルを文字列から数値に変換\n",
    "class_mapping_y = {'Iris-versicolor':1, 'Iris-virginica':2, 'Iris-setosa':3}\n",
    "y = y.copy()\n",
    "\n",
    "# loc関数で'class'列のみを選択して、変数class_mapping_yをmap関数で適用する\n",
    "y.loc[:,'class'] = y['class'].map(class_mapping_y)\n",
    "\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.tsvの読み込み\n",
    "test_df = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスを説明変数から削除して、特徴量のみをtestXに代入する\n",
    "testX = test_df.iloc[:, 1:]\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列の桁数確認\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎統計量の確認\n",
    "testX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 統計量からわかること\n",
    "- 特徴量は４つのみ (がく片の長さ、がく片の幅、花弁の長さ、花弁の幅)でtrainデータと同じ\n",
    "- 特徴量の中では sepal width in cm (がく片の長さ)のバラつきが比較的小さい\n",
    "- 特徴量の中では petal length in cm (花弁の長さ)のバラつきが比較的大きい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型の確認\n",
    "testX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべて小数点型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "testX.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データに欠損値はないことを確認。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainデータの交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉検証　Holdout法\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(trainX,\n",
    "                                                 y,\n",
    "                                                 test_size=0.30,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整形\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリからアルゴリズムの読み込み\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# set pipelines for different algorithms\n",
    "pipe_LR = Pipeline([('scl',StandardScaler()),\n",
    "                       ('est',LogisticRegression(random_state=1))])\n",
    "pipe_RF = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',RandomForestClassifier(random_state=1))])\n",
    "pipe_GB = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',GradientBoostingClassifier(random_state=1))])\n",
    "pipe_PCARF = Pipeline([('scl',StandardScaler()),\n",
    "                          ('pca',PCA(random_state=1)),\n",
    "                          ('est',RandomForestClassifier(random_state=1))])\n",
    "pipe_PCAGB = Pipeline([('scl',StandardScaler()),\n",
    "                          ('pca',PCA(random_state=1)),\n",
    "                          ('est',GradientBoostingClassifier(random_state=1))])\n",
    "pipe_SVC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',LinearSVC(random_state=1))])\n",
    "pipe_KNC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelineの学習\n",
    "pipe_LR.fit(X_train, y_train)\n",
    "pipe_RF.fit(X_train, y_train)\n",
    "pipe_GB.fit(X_train, y_train)\n",
    "pipe_PCARF.fit(X_train, y_train)\n",
    "pipe_PCAGB.fit(X_train, y_train)\n",
    "pipe_SVC.fit(X_train, y_train)\n",
    "pipe_KNC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe_LR_Train:0.865\n",
      "pipe_LR_Test:0.826\n",
      "pipe_RF_Train:0.981\n",
      "pipe_RF_Test:0.870\n",
      "pipe_GB_Train:1.000\n",
      "pipe_GB_Test:0.913\n",
      "pipe_PCARF_Train:1.000\n",
      "pipe_PCARF_Test:1.000\n",
      "pipe_PCAGB_Train:1.000\n",
      "pipe_PCAGB_Test:0.957\n",
      "pipe_SVC_Train:0.962\n",
      "pipe_SVC_Test:0.957\n",
      "pipe_KNC_Train:0.981\n",
      "pipe_KNC_Test:0.957\n"
     ]
    }
   ],
   "source": [
    "# 評価（accuracyスコアとする）\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('pipe_LR_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_LR.predict(X_train)))\n",
    "print('pipe_LR_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_LR.predict(X_test)))\n",
    "\n",
    "print('pipe_RF_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_RF.predict(X_train)))\n",
    "print('pipe_RF_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_RF.predict(X_test)))\n",
    "\n",
    "print('pipe_GB_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_GB.predict(X_train)))\n",
    "print('pipe_GB_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_GB.predict(X_test)))\n",
    "\n",
    "print('pipe_PCARF_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_PCARF.predict(X_train)))\n",
    "print('pipe_PCARF_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_PCARF.predict(X_test)))\n",
    "\n",
    "print('pipe_PCAGB_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_PCAGB.predict(X_train)))\n",
    "print('pipe_PCAGB_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_PCAGB.predict(X_test)))\n",
    "\n",
    "print('pipe_SVC_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_SVC.predict(X_train)))\n",
    "print('pipe_SVC_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_SVC.predict(X_test)))\n",
    "\n",
    "print('pipe_KNC_Train:%.3f'% accuracy_score(y_train,\n",
    "                                          pipe_KNC.predict(X_train)))\n",
    "print('pipe_KNC_Test:%.3f' % accuracy_score(y_test,\n",
    "                                          pipe_KNC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe_PCARFを採用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータグリッドの設定\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# paramG = {'n_estimators':[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "\n",
    "param_grid_PCARF = {'pca__n_components':[2,3,4],\n",
    "                    'est__n_estimators': [5, 10, 20, 30, 50, 100],\n",
    "#                     'est__max_features': [2,3,4],\n",
    "                    'est__random_state': [1],# 乱数のシードです。\n",
    "                    'est__n_jobs': [-1],# 複数のCPUコアを使って並列に学習します。-1は最大値。\n",
    "                    'est__min_samples_split' : [3, 5, 10, 15, 20, 25, 30, 40, 50, 100],\n",
    "                    'est__max_depth' : [3, 5, 10, 15, 20, 25, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCVの設定\n",
    "print('探索空間:%s' %param_grid_PCARF)\n",
    "clf = GridSearchCV(estimator=pipe_PCARF,# 対象の機械学習モデル\n",
    "                   param_grid=param_grid_PCARF,# 探索パラメータ辞書\n",
    "                   scoring='accuracy',\n",
    "                   cv=3,# クロスバリデーションの分割数\n",
    "                   return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8846153846153846\n",
      "Best Params {'est__max_depth': 3, 'est__min_samples_split': 3, 'est__n_estimators': 50, 'est__n_jobs': -1, 'est__random_state': 1, 'pca__n_components': 2}\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print('Best Score:', clf.best_score_)\n",
    "print('Best Params', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数predに予測値を代入\n",
    "pred = pipe_RF.predict(testX)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出用CSVの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用CSVの読み込み\n",
    "sample = pd.read_csv(\"sample_submit.csv\",header=None)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array形で格納されているpredをDataFrame型に変換\n",
    "pred_df = pd.DataFrame(pred)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値を文字列に変換\n",
    "# 提出用データはIrisの品種名でデータを入力する必要があるため数値から文字列に変換する。\n",
    "# 正解ラベルの数値数値変換\n",
    "class_mapping_y2 = {1:'Iris-versicolor', 2:'Iris-virginica', 3:'Iris-setosa'}\n",
    "pred_df = pred_df.copy()\n",
    "\n",
    "# loc関数で'0'列のみを選択して、変数class_mappingをmap関数で適用する\n",
    "pred_df.iloc[:,0] = pred_df[0].map(class_mapping_y2)\n",
    "\n",
    "display(pred_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用csvの正解カラム'1'にpredを代入\n",
    "sample[1] = pred_df\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用データをcsv形式で出力\n",
    "sample.to_csv(\"submit2.csv\",index=None,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
