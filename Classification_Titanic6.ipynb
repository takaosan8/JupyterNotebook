{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crassification Titanic\n",
    "　　　From SIGNATE　【練習問題】タイタニックの生存予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.tsvの読み込み\n",
    "train_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスとy（目的変数）を説明変数から削除して、特徴量のみをtrainXに代入する\n",
    "trainX = train_df.iloc[:, 2:]\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列の桁数確認\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎統計量の確認\n",
    "trainX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 統計量からわかること\n",
    "- numericな特徴量は５つのみ (客室のクラス（1,2,3の順に高級クラス）、年齢、乗船していた兄弟配偶者の数、乗船していた両親子供の数、運賃)\n",
    "- 特徴量の中では pclass (客室のクラス)、parchの(乗船していた両親子供の数)バラつきが比較的小さい\n",
    "- 特徴量の中では fare (運賃)のバラつきが比較的大きい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型の確認\n",
    "trainX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整数型、小数点型、文字列などが混在している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"age\",\"embarked\"に欠損値を含む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainデータの目的変数をyに代入する\n",
    "y = train_df.iloc[:,[1]]\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性別カラムの種別個数を確認\n",
    "trainX[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗船地カラムの種別個数を確認\n",
    "trainX[\"embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オブジェクト型の特徴量を数値型に変換\n",
    "class_mapping_sex = {\"male\":0 ,\"female\":1}\n",
    "class_mapping_emb = {\"S\": 0, \"C\": 1, \"Q\": 2} \n",
    "\n",
    "trainX = trainX.copy()\n",
    "\n",
    "# loc関数で'該当'列のみを選択して、変数class_mapping_sex,embをmap関数で適用する\n",
    "trainX.loc[:,\"sex\"] =trainX[\"sex\"].map(class_mapping_sex)\n",
    "trainX.loc[:,\"embarked\"] = trainX[\"embarked\"].map(class_mapping_emb)\n",
    "\n",
    "display(trainX.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainXの欠損値のあるカラム'age'の平均値を求め、変数avg1に代入\n",
    "avg1 = trainX[\"age\"].mean()\n",
    "avg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数avgをnullであるカラムに穴埋めする\n",
    "trainX.loc[:,\"age\"] = trainX[\"age\"].fillna(avg1)\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputerを使用してembarkedの欠損値を最頻値で置き換える\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# インピュータークラスの実体化\n",
    "# 欠損値'NaN'を最頻値('most_frequent')で置き換える,処理は列方向(axis=0)で行う.\n",
    "imp = Imputer(missing_values='NaN',\n",
    "               strategy='most_frequent',\n",
    "               axis=0)\n",
    "\n",
    "# 各特徴量の平均値を学習\n",
    "imp.fit(trainX)\n",
    "\n",
    "# 学習済みのImputerを適用し, 欠損値を置き換える.\n",
    "mfq_columns = trainX.columns.values\n",
    "trainX2 = pd.DataFrame(imp.transform(trainX),\n",
    "                     columns=mfq_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果表示\n",
    "trainX2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "trainX2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.tsvの読み込み\n",
    "test_df = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスを説明変数から削除して、特徴量のみをtestXに代入する\n",
    "testX = test_df.iloc[:, 1:]\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列の桁数確認\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎統計量の確認\n",
    "testX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 統計量からわかること\n",
    "- numericな特徴量は５つのみ (客室のクラス（1,2,3の順に高級クラス）、年齢、乗船していた兄弟配偶者の数、乗船していた両親子供の数、運賃)\n",
    "- 特徴量の中では pclass (客室のクラス)、parchの(乗船していた両親子供の数)バラつきが比較的小さい\n",
    "- 特徴量の中では fare (運賃)のバラつきが比較的大きい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型の確認\n",
    "testX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整数型、小数点型、文字列などが混在している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "testX.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"age\"に欠損値があることを確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オブジェクト型の特徴量を数値型に変換\n",
    "# class_mapping_sex = {\"male\":0 ,\"female\":1}\n",
    "# class_mapping_emb = {\"S\": 0, \"C\": 1, \"Q\": 2} \n",
    "\n",
    "testX = testX.copy()\n",
    "\n",
    "# loc関数で該当列のみを選択して、変数class_mapping_sex,embをmap関数で適用する\n",
    "testX.loc[:,\"sex\"] =testX[\"sex\"].map(class_mapping_sex)\n",
    "testX.loc[:,\"embarked\"] = testX[\"embarked\"].map(class_mapping_emb)\n",
    "\n",
    "display(testX.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainXの欠損値のあるカラム'age'の平均値を求め、変数avg2に代入\n",
    "avg2 = testX[\"age\"].mean()\n",
    "avg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数avg2をnullであるカラムに穴埋めする\n",
    "testX.loc[:,\"age\"] = testX[\"age\"].fillna(avg2)\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の確認\n",
    "testX.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainデータの交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉検証　Holdout法\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(trainX2,\n",
    "                                                 y,\n",
    "                                                 test_size=0.30,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整形\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリからアルゴリズムの読み込み\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# set pipelines for different algorithms\n",
    "pipe_LR = Pipeline([('scl',StandardScaler()),\n",
    "                       ('est',LogisticRegression(random_state=1))])\n",
    "pipe_RF = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',RandomForestClassifier(random_state=1))])\n",
    "pipe_GB = Pipeline([('scl',StandardScaler()),\n",
    "                        ('est',GradientBoostingClassifier(random_state=1))])\n",
    "pipe_PCARF = Pipeline([('scl',StandardScaler()),\n",
    "                          ('pca',PCA(random_state=1)),\n",
    "                          ('est',RandomForestClassifier(random_state=1))])\n",
    "pipe_PCAGB = Pipeline([('scl',StandardScaler()),\n",
    "                          ('pca',PCA(random_state=1)),\n",
    "                          ('est',GradientBoostingClassifier(random_state=1))])\n",
    "pipe_SVC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',SVC(random_state=1))])\n",
    "pipe_LSVC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',LinearSVC(random_state=1))])\n",
    "pipe_KNC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',KNeighborsClassifier())])\n",
    "pipe_GNB = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',GaussianNB())])\n",
    "pipe_PER = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',Perceptron(random_state=1))])\n",
    "pipe_SGD = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',SGDClassifier(random_state=1))])\n",
    "pipe_DTC = Pipeline([('scl',StandardScaler()),\n",
    "                          ('est',DecisionTreeClassifier(random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelineの学習\n",
    "pipe_LR.fit(X_train, y_train)\n",
    "pipe_RF.fit(X_train, y_train)\n",
    "pipe_GB.fit(X_train, y_train)\n",
    "pipe_PCARF.fit(X_train, y_train)\n",
    "pipe_PCAGB.fit(X_train, y_train)\n",
    "pipe_SVC.fit(X_train, y_train)\n",
    "pipe_LSVC.fit(X_train, y_train)\n",
    "pipe_KNC.fit(X_train, y_train)\n",
    "pipe_GNB.fit(X_train, y_train)\n",
    "pipe_PER.fit(X_train, y_train)\n",
    "pipe_SGD.fit(X_train, y_train)\n",
    "pipe_DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "pipe_LR_Train:0.793\n",
      "pipe_LR_Test:0.763\n",
      "----------------------------------------\n",
      "pipe_RF_Train:0.977\n",
      "pipe_RF_Test:0.705\n",
      "----------------------------------------\n",
      "pipe_GB_Train:0.922\n",
      "pipe_GB_Test:0.747\n",
      "----------------------------------------\n",
      "pipe_PCARF_Train:0.974\n",
      "pipe_PCARF_Test:0.735\n",
      "----------------------------------------\n",
      "pipe_PCAGB_Train:0.974\n",
      "pipe_PCAGB_Test:0.705\n",
      "----------------------------------------\n",
      "pipe_SVC_Train:0.841\n",
      "pipe_SVC_Test:0.791\n",
      "----------------------------------------\n",
      "pipe_LSVC_Train:0.796\n",
      "pipe_LSVC_Test:0.773\n",
      "----------------------------------------\n",
      "pipe_KNC_Train:0.872\n",
      "pipe_KNC_Test:0.739\n",
      "----------------------------------------\n",
      "pipe_GNB_Train:0.800\n",
      "pipe_GNB_Test:0.733\n",
      "----------------------------------------\n",
      "pipe_PER_Train:0.671\n",
      "pipe_PER_Test:0.685\n",
      "----------------------------------------\n",
      "pipe_SGD_Train:0.684\n",
      "pipe_SGD_Test:0.625\n",
      "----------------------------------------\n",
      "pipe_DTC_Train:0.992\n",
      "pipe_DTC_Test:0.689\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 評価（roc_aucスコアとする）\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('-'*40)\n",
    "print('pipe_LR_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_LR.predict(X_train)))\n",
    "print('pipe_LR_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_LR.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_RF_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_RF.predict(X_train)))\n",
    "print('pipe_RF_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_RF.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_GB_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_GB.predict(X_train)))\n",
    "print('pipe_GB_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_GB.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_PCARF_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_PCARF.predict(X_train)))\n",
    "print('pipe_PCARF_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_PCARF.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_PCAGB_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_PCAGB.predict(X_train)))\n",
    "print('pipe_PCAGB_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_PCAGB.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_SVC_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_SVC.predict(X_train)))\n",
    "print('pipe_SVC_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_SVC.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_LSVC_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_LSVC.predict(X_train)))\n",
    "print('pipe_LSVC_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_LSVC.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_KNC_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_KNC.predict(X_train)))\n",
    "print('pipe_KNC_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_KNC.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_GNB_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_GNB.predict(X_train)))\n",
    "print('pipe_GNB_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_GNB.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_PER_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_PER.predict(X_train)))\n",
    "print('pipe_PER_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_PER.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_SGD_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_SGD.predict(X_train)))\n",
    "print('pipe_SGD_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_SGD.predict(X_test)))\n",
    "print('-'*40)\n",
    "print('pipe_DTC_Train:%.3f'% roc_auc_score(y_train,\n",
    "                                          pipe_DTC.predict(X_train)))\n",
    "print('pipe_DTC_Test:%.3f' % roc_auc_score(y_test,\n",
    "                                          pipe_DTC.predict(X_test)))\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe_SVCを採用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータグリッドの設定\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_SVC=[{\n",
    "                 'est__kernel':['linear','rbf','poly','sigmoid'],\n",
    "                 'est__C':[1.0,0.1,0.01]\n",
    "                }] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('探索空間:%s' %param_grid_SVC)\n",
    "gs=GridSearchCV(estimator=pipe_SVC,\n",
    "                param_grid=param_grid_SVC,\n",
    "                scoring='accuracy',\n",
    "                cv=3,\n",
    "                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8134831460674158\n",
      "Best Params {'est__C': 1.0, 'est__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "gs=gs.fit(trainX2,y.values.ravel())\n",
    "\n",
    "# 探索した結果のベストスコアとパラメータの取得\n",
    "print('Best Score:', gs.best_score_)\n",
    "print('Best Params', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 変数predに予測値を代入\n",
    "pred = pipe_SVC.predict(testX)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出用CSVの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用CSVの読み込み\n",
    "sample = pd.read_csv(\"sample_submit.tsv\", sep=\"\\t\", header=None)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用csvの正解カラム'1'にpredを代入\n",
    "sample[1] = pred\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"submit6.csv\",index=None,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
